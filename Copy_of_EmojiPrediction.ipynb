{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz51hfOu3tdz2wp/9PitJv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshitaJha1405/Emoji-Predictor/blob/main/Copy_of_EmojiPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-I9kN1X9U985",
        "outputId": "4a4e8191-762c-447f-a112-b64427324e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution:\n",
            " Label\n",
            "2    55\n",
            "3    43\n",
            "0    28\n",
            "4    22\n",
            "1    18\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1453\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1453\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1454 (\u001b[38;5;33mEmbedding\u001b[0m)      │ ?                      │        \u001b[38;5;34m29,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2907 (\u001b[38;5;33mLSTM\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2908 (\u001b[38;5;33mLSTM\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1453 (\u001b[38;5;33mDense\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1454 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2907 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2908 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1453 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,500\u001b[0m (115.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,500</span> (115.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m29,500\u001b[0m (115.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,500</span> (115.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - accuracy: 0.2399 - loss: 1.6127 - val_accuracy: 0.3235 - val_loss: 1.5184\n",
            "Epoch 2/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3005 - loss: 1.5442 - val_accuracy: 0.3235 - val_loss: 1.4970\n",
            "Epoch 3/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2812 - loss: 1.5307 - val_accuracy: 0.3235 - val_loss: 1.4833\n",
            "Epoch 4/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3256 - loss: 1.5069 - val_accuracy: 0.2941 - val_loss: 1.4616\n",
            "Epoch 5/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3833 - loss: 1.4562 - val_accuracy: 0.4118 - val_loss: 1.4409\n",
            "Epoch 6/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4719 - loss: 1.3841 - val_accuracy: 0.4118 - val_loss: 1.4260\n",
            "Epoch 7/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5294 - loss: 1.3214 - val_accuracy: 0.3529 - val_loss: 1.4260\n",
            "Epoch 8/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5309 - loss: 1.2767 - val_accuracy: 0.2353 - val_loss: 1.4231\n",
            "Epoch 9/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5860 - loss: 1.1749 - val_accuracy: 0.4118 - val_loss: 1.4063\n",
            "Epoch 10/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5642 - loss: 1.1148 - val_accuracy: 0.3529 - val_loss: 1.3991\n",
            "Epoch 11/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5994 - loss: 1.0974 - val_accuracy: 0.3824 - val_loss: 1.4081\n",
            "Epoch 12/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6007 - loss: 1.0020 - val_accuracy: 0.4118 - val_loss: 1.3667\n",
            "Epoch 13/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7631 - loss: 0.8812 - val_accuracy: 0.4412 - val_loss: 1.3213\n",
            "Epoch 14/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7467 - loss: 0.7703 - val_accuracy: 0.4118 - val_loss: 1.3865\n",
            "Epoch 15/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6856 - loss: 0.8127 - val_accuracy: 0.5294 - val_loss: 1.3017\n",
            "Epoch 16/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7650 - loss: 0.7337 - val_accuracy: 0.5588 - val_loss: 1.2297\n",
            "Epoch 17/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7481 - loss: 0.6954 - val_accuracy: 0.5000 - val_loss: 1.2287\n",
            "Epoch 18/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7170 - loss: 0.7280 - val_accuracy: 0.5882 - val_loss: 1.2800\n",
            "Epoch 19/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7853 - loss: 0.6774 - val_accuracy: 0.5000 - val_loss: 1.2484\n",
            "Epoch 20/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7499 - loss: 0.7811 - val_accuracy: 0.3824 - val_loss: 1.5191\n",
            "Epoch 21/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7098 - loss: 0.8360 - val_accuracy: 0.5588 - val_loss: 1.1029\n",
            "Epoch 22/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8311 - loss: 0.5491 - val_accuracy: 0.5882 - val_loss: 1.1810\n",
            "Epoch 23/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7805 - loss: 0.6144 - val_accuracy: 0.6176 - val_loss: 1.1484\n",
            "Epoch 24/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8502 - loss: 0.5820 - val_accuracy: 0.4706 - val_loss: 1.1541\n",
            "Epoch 25/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8313 - loss: 0.5274 - val_accuracy: 0.6765 - val_loss: 1.0069\n",
            "Epoch 26/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8717 - loss: 0.5070 - val_accuracy: 0.5882 - val_loss: 1.1301\n",
            "Epoch 27/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8411 - loss: 0.5000 - val_accuracy: 0.5882 - val_loss: 1.1351\n",
            "Epoch 28/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8922 - loss: 0.4036 - val_accuracy: 0.5882 - val_loss: 1.1210\n",
            "Epoch 29/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8875 - loss: 0.4257 - val_accuracy: 0.6765 - val_loss: 1.0764\n",
            "Epoch 30/30\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9115 - loss: 0.3855 - val_accuracy: 0.6471 - val_loss: 1.0557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step\n",
            "Input: i feel good | Predicted Emoji: 😃\n",
            "Input: i love you | Predicted Emoji: ❤️\n",
            "Input: let's eat dinner | Predicted Emoji: 🍽️\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM, SimpleRNN, Embedding, Dropout\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv('/content/sample_data/emoji_data.csv',header = None)\n",
        "data.columns = ['Text', 'Label']\n",
        "data = data.dropna()\n",
        "data = data[data['Label'].apply(lambda x: str(x).isdigit())]\n",
        "\n",
        "X = data['Text'].values\n",
        "Y = data['Label'].values.astype(int)\n",
        "\n",
        "X = [x.lower() for x in X]\n",
        "\n",
        "emoji_dict = {\n",
        "    0: \":red_heart:\",\n",
        "    1: \":baseball:\",\n",
        "    2: \":grinning_face_with_big_eyes:\",\n",
        "    3: \":disappointed_face:\",\n",
        "    4: \":fork_and_knife_with_plate:\"\n",
        "}\n",
        "\n",
        "def label_to_emoji(label):\n",
        "  return emoji.emojize(emoji_dict[label])\n",
        "\n",
        "\n",
        "#Embeddings\n",
        "#file = open('/content/sample_data/glove.6B.100d.txt','r', encoding = 'utf8')\n",
        "#content = file.readlines()\n",
        "#file.close()\n",
        "\n",
        "# content\n",
        "\n",
        "embeddings = {}\n",
        "with open('/content/sample_data/glove.6B.100d.txt','r', encoding = 'utf8') as file:\n",
        "  for line in file:\n",
        "    split_line = line.split()\n",
        "    word = split_line[0]\n",
        "    vector = np.array(split_line[1:], dtype = float)\n",
        "    embeddings[word] = vector\n",
        "\n",
        "  #def get_maxlen(data):\n",
        "    #maxlen = 0\n",
        "    #for sent in data:\n",
        "        #maxlen = max(maxlen, len(sent))\n",
        "    #return max(len(sent) for sent in data)\n",
        "\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(X)\n",
        "  word2index = tokenizer.word_index\n",
        "  Xtokens = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "  maxlen = max(len(sent) for sent in Xtokens)\n",
        "  Xtrain = pad_sequences(Xtokens, maxlen = maxlen,  padding = 'post', truncating = 'post')\n",
        "  Ytrain = to_categorical(Y)\n",
        "\n",
        "  #check dataset\n",
        "  print(\"Label distribution:\\n\", data['Label'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "  #Model\n",
        "  embed_size = 100\n",
        "  embedding_matrix = np.zeros((len(word2index)+1, embed_size))\n",
        "\n",
        "  for word, i in word2index.items():\n",
        "      embed_vector = embeddings.get(word)\n",
        "      if embed_vector is not None:\n",
        "          embedding_matrix[i] = embed_vector\n",
        "\n",
        "\n",
        "  model = Sequential([\n",
        "    Embedding(input_dim = len(word2index) + 1,\n",
        "              output_dim = embed_size,\n",
        "              input_length = maxlen,\n",
        "              weights = [embedding_matrix],\n",
        "              trainable = False),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.5),\n",
        "    LSTM(32),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  #Train\n",
        "  model.fit(Xtrain, Ytrain, epochs = 30, batch_size = 32, validation_split=0.2)\n",
        "\n",
        "  model.save('emoji_model.h5')\n",
        "\n",
        "  import pickle\n",
        "  with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "\n",
        "\n",
        "  #Test\n",
        "  test_sentences = [\"I feel good\", \"I Love You\", \"let's eat dinner\"]\n",
        "  test_sentences = [s.lower() for s in test_sentences]\n",
        "\n",
        "\n",
        "  test_tokens = tokenizer.texts_to_sequences(test_sentences)\n",
        "  Xtest = pad_sequences(test_tokens, maxlen=maxlen, padding='post', truncating='post')\n",
        "\n",
        "  predictions = model.predict(Xtest)\n",
        "  predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "  # Output predictions\n",
        "  for i, sentence in enumerate(test_sentences):\n",
        "      print(f\"Input: {sentence} | Predicted Emoji: {label_to_emoji(predicted_labels[i])}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade emoji\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYl0u9CRd0dS",
        "outputId": "8c402583-26dd-4af9-9a98-473b826ce232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n"
          ]
        }
      ]
    }
  ]
}